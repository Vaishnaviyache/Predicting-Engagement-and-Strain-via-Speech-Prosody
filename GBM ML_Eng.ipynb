{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8a5e2f-acd2-4a1b-a1a8-52ae25d64845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resilience_category\n",
      "2    25\n",
      "1    21\n",
      "0    20\n",
      "Name: count, dtype: int64\n",
      "cognitive_load_category\n",
      "2    26\n",
      "0    22\n",
      "1    18\n",
      "Name: count, dtype: int64\n",
      "Resilience Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55         6\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.27      0.43      0.33         7\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.29      0.31      0.29        20\n",
      "weighted avg       0.28      0.30      0.28        20\n",
      "\n",
      "Resilience Accuracy: 0.3\n",
      "\n",
      "Cognitive Load Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33         5\n",
      "           1       0.29      0.29      0.29         7\n",
      "           2       0.17      0.12      0.14         8\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.25      0.27      0.25        20\n",
      "weighted avg       0.24      0.25      0.24        20\n",
      "\n",
      "Cognitive Load Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the feature dataset\n",
    "df_eng = pd.read_excel(\"C:/Users/vyache/Downloads/Features_English.xlsx\")\n",
    "\n",
    "# Select only feature columns (replace 'feature_cols' with the actual list of columns)\n",
    "feature_cols = df_eng.columns.difference([\"Recording\", \"Speaker\"])  # Exclude non-feature columns\n",
    "\n",
    "# Standardize the features before applying PCA\n",
    "scaler = StandardScaler()\n",
    "df_eng_scaled = scaler.fit_transform(df_eng[feature_cols])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)  # Adjust number of components as needed\n",
    "principal_components = pca.fit_transform(df_eng_scaled)\n",
    "\n",
    "# Convert PCA output to DataFrame\n",
    "df_pca = pd.DataFrame(principal_components, columns=[f\"PC{i+1}\" for i in range(3)])\n",
    "\n",
    "# Add back identifiers (Recording, Speaker) for merging\n",
    "df_pca[\"Recording\"] = df_eng[\"Recording\"]\n",
    "df_pca[\"Speaker\"] = df_eng[\"Speaker\"]\n",
    "\n",
    "# Load self-report dataset\n",
    "df_self_reports = pd.read_excel(\"C:/Users/vyache/Desktop/Questionnaire data_Eng.xlsx\")\n",
    "\n",
    "# Merge PCA-transformed features with self-reports\n",
    "df_merged = pd.merge(df_pca, df_self_reports, on=[\"Recording\", \"Speaker\"])\n",
    "\n",
    "# Define thresholds for resilience and cognitive load\n",
    "low_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.33)\n",
    "high_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.66)\n",
    "\n",
    "low_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.33)\n",
    "high_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.66)\n",
    "\n",
    "# Categorization functions\n",
    "def categorize_resilience(score):\n",
    "    if score < low_threshold_resilience:\n",
    "        return 0  # Low\n",
    "    elif score < high_threshold_resilience:\n",
    "        return 1  # Medium\n",
    "    else:\n",
    "        return 2  # High\n",
    "\n",
    "def categorize_cognitive_load(score):\n",
    "    if score < low_threshold_load:\n",
    "        return 0  # Low\n",
    "    elif score < high_threshold_load:\n",
    "        return 1  # Medium\n",
    "    else:\n",
    "        return 2  # High\n",
    "\n",
    "# Apply categorization\n",
    "df_merged[\"resilience_category\"] = df_merged[\"Emotional Resilience\"].apply(categorize_resilience)\n",
    "df_merged[\"cognitive_load_category\"] = df_merged[\"Cognitive Load\"].apply(categorize_cognitive_load)\n",
    "\n",
    "# Verify categories\n",
    "print(df_merged[\"resilience_category\"].value_counts())\n",
    "print(df_merged[\"cognitive_load_category\"].value_counts())\n",
    "\n",
    "# Select PCA features\n",
    "X = df_merged[[\"PC1\", \"PC2\", \"PC3\"]]\n",
    "y_resilience = df_merged[\"resilience_category\"]\n",
    "y_cognitive_load = df_merged[\"cognitive_load_category\"]\n",
    "\n",
    "# Standardize PCA features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split for Resilience Classification\n",
    "X_train_resilience, X_test_resilience, y_train_resilience, y_test_resilience = train_test_split(X_scaled, y_resilience, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Gradient Boosting Classifier for Resilience\n",
    "gbm_resilience = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on training data for Resilience\n",
    "gbm_resilience.fit(X_train_resilience, y_train_resilience)\n",
    "\n",
    "# Predict on test set for Resilience\n",
    "y_pred_resilience = gbm_resilience.predict(X_test_resilience)\n",
    "\n",
    "# Evaluate the model for Resilience\n",
    "print(\"Resilience Classification Report:\")\n",
    "print(classification_report(y_test_resilience, y_pred_resilience))\n",
    "\n",
    "# Evaluate accuracy for Resilience\n",
    "accuracy_resilience = accuracy_score(y_test_resilience, y_pred_resilience)\n",
    "print(f\"Resilience Accuracy: {accuracy_resilience}\")\n",
    "\n",
    "# Train-Test Split for Cognitive Load Classification\n",
    "X_train_load, X_test_load, y_train_load, y_test_load = train_test_split(X_scaled, y_cognitive_load, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Gradient Boosting Classifier for Cognitive Load\n",
    "gbm_load = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on training data for Cognitive Load\n",
    "gbm_load.fit(X_train_load, y_train_load)\n",
    "\n",
    "# Predict on test set for Cognitive Load\n",
    "y_pred_load = gbm_load.predict(X_test_load)\n",
    "\n",
    "# Evaluate the model for Cognitive Load\n",
    "print(\"\\nCognitive Load Classification Report:\")\n",
    "print(classification_report(y_test_load, y_pred_load))\n",
    "\n",
    "# Evaluate accuracy for Cognitive Load\n",
    "accuracy_load = accuracy_score(y_test_load, y_pred_load)\n",
    "print(f\"Cognitive Load Accuracy: {accuracy_load}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36753728-b822-4650-920d-b39c3e0ddacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Resilience classification: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(gbm, param_grid, cv=5)\n",
    "grid_search.fit(X_train_resilience, y_train_resilience)\n",
    "\n",
    "print(f\"Best parameters for Resilience classification: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afc029d-471f-4091-8796-735526ae0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resilience Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.20      0.14      0.17         7\n",
      "           2       0.40      0.57      0.47         7\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.33      0.35      0.33        20\n",
      "weighted avg       0.33      0.35      0.33        20\n",
      "\n",
      "Resilience Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split for Resilience Classification\n",
    "X_train_resilience, X_test_resilience, y_train_resilience, y_test_resilience = train_test_split(X_scaled, y_resilience, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Gradient Boosting Classifier with the best parameters\n",
    "gbm_resilience = GradientBoostingClassifier(\n",
    "    learning_rate=0.1, \n",
    "    max_depth=3,  # Or try even smaller values like 2\n",
    "    n_estimators=50,\n",
    "    random_state=42,\n",
    "  # Handle class imbalance\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on training data for Resilience\n",
    "gbm_resilience.fit(X_train_resilience, y_train_resilience)\n",
    "\n",
    "# Predict on test set for Resilience\n",
    "y_pred_resilience = gbm_resilience.predict(X_test_resilience)\n",
    "\n",
    "# Evaluate the model for Resilience\n",
    "print(\"Resilience Classification Report:\")\n",
    "print(classification_report(y_test_resilience, y_pred_resilience))\n",
    "\n",
    "# Evaluate accuracy for Resilience\n",
    "accuracy_resilience = accuracy_score(y_test_resilience, y_pred_resilience)\n",
    "print(f\"Resilience Accuracy: {accuracy_resilience}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbacb5-7046-4635-93f6-7a7e8cb66200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
