{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4eec9b-99e3-409a-8ffd-e9dc7dd1393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a61a50d-1178-4252-bd28-86d49710abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resilience_category\n",
      "0    40\n",
      "1    24\n",
      "Name: count, dtype: int64\n",
      "cognitive_load_category\n",
      "0    39\n",
      "1    25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the feature dataset\n",
    "df_eng = pd.read_excel(\"C:/Users/vyache/Downloads/Features_German.xlsx\")\n",
    "\n",
    "# Select only feature columns (replace 'feature_cols' with the actual list of columns)\n",
    "feature_cols = df_eng.columns.difference([\"Recording\", \"Speaker\"])  # Exclude non-feature columns\n",
    "\n",
    "# Standardize the features before applying PCA\n",
    "scaler = StandardScaler()\n",
    "df_eng_scaled = scaler.fit_transform(df_eng[feature_cols])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)  # Adjust number of components as needed\n",
    "principal_components = pca.fit_transform(df_eng_scaled)\n",
    "\n",
    "# Convert PCA output to DataFrame\n",
    "df_pca = pd.DataFrame(principal_components, columns=[f\"PC{i+1}\" for i in range(3)])\n",
    "\n",
    "# Add back identifiers (Recording, Speaker) for merging\n",
    "df_pca[\"Recording\"] = df_eng[\"Recording\"]\n",
    "df_pca[\"Speaker\"] = df_eng[\"Speaker\"]\n",
    "\n",
    "# Load self-report dataset\n",
    "df_self_reports = pd.read_excel(\"C:/Users/vyache/Desktop/Questionnaire data_Ger.xlsx\")\n",
    "\n",
    "# Merge PCA-transformed features with self-reports\n",
    "df_merged = pd.merge(df_pca, df_self_reports, on=[\"Recording\", \"Speaker\"])\n",
    "\n",
    "# Define thresholds for resilience and cognitive load\n",
    "low_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.33)\n",
    "high_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.66)\n",
    "\n",
    "low_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.33)\n",
    "high_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.66)\n",
    "\n",
    "# Categorization functions for 2 categories (Low vs High)\n",
    "def categorize_resilience(score):\n",
    "    if score < high_threshold_resilience:  # Low resilience\n",
    "        return 0  # Low\n",
    "    else:  # High resilience\n",
    "        return 1  # High\n",
    "\n",
    "def categorize_cognitive_load(score):\n",
    "    if score < high_threshold_load:  # Low cognitive load\n",
    "        return 0  # Low\n",
    "    else:  # High cognitive load\n",
    "        return 1  # High\n",
    "# Apply categorization\n",
    "df_merged[\"resilience_category\"] = df_merged[\"Emotional Resilience\"].apply(categorize_resilience)\n",
    "df_merged[\"cognitive_load_category\"] = df_merged[\"Cognitive Load\"].apply(categorize_cognitive_load)\n",
    "\n",
    "# Verify categories\n",
    "print(df_merged[\"resilience_category\"].value_counts())\n",
    "print(df_merged[\"cognitive_load_category\"].value_counts())\n",
    "\n",
    "# Select PCA features\n",
    "X = df_merged[[\"PC1\", \"PC2\", \"PC3\"]]\n",
    "y_resilience = df_merged[\"resilience_category\"]\n",
    "y_cognitive_load = df_merged[\"cognitive_load_category\"]\n",
    "\n",
    "# Standardize PCA features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6d6b95-81e7-49eb-adeb-4b3708082620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for resilience classification\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(\n",
    "    X_scaled, y_resilience, test_size=0.2, random_state=42, stratify=y_resilience\n",
    ")\n",
    "\n",
    "# Split data for cognitive load classification\n",
    "X_train_cog, X_test_cog, y_train_cog, y_test_cog = train_test_split(\n",
    "    X_scaled, y_cognitive_load, test_size=0.2, random_state=42, stratify=y_cognitive_load\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f3aae0-e407-4742-879e-74259de3e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resilience Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67         8\n",
      "           1       0.50      0.60      0.55         5\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.61      0.61      0.61        13\n",
      "weighted avg       0.63      0.62      0.62        13\n",
      "\n",
      "Accuracy: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier for resilience\n",
    "svm_res = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_res = svm_res.predict(X_test_res)\n",
    "\n",
    "# Evaluate resilience classification performance\n",
    "print(\"Resilience Classification Report:\")\n",
    "print(classification_report(y_test_res, y_pred_res))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_res, y_pred_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd15babc-6ad1-4dc2-868a-73ec2d0da8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognitive Load Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57         8\n",
      "           1       0.43      0.60      0.50         5\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.55      0.55      0.54        13\n",
      "weighted avg       0.58      0.54      0.54        13\n",
      "\n",
      "Accuracy: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier for cognitive load\n",
    "svm_cog = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm_cog.fit(X_train_cog, y_train_cog)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_cog = svm_cog.predict(X_test_cog)\n",
    "\n",
    "# Evaluate cognitive load classification performance\n",
    "print(\"Cognitive Load Classification Report:\")\n",
    "print(classification_report(y_test_cog, y_pred_cog))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cog, y_pred_cog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c324dd9-1ac7-4264-a153-e2f06c44b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res_bal, y_train_res_bal = smote.fit_resample(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc72ad0f-3c21-4518-b92b-6b0d4ff83cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Improved Resilience Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67         8\n",
      "           1       0.50      0.60      0.55         5\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.61      0.61      0.61        13\n",
      "weighted avg       0.63      0.62      0.62        13\n",
      "\n",
      "Accuracy: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Run GridSearch\n",
    "grid_search = GridSearchCV(SVC(class_weight='balanced'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_res_bal, y_train_res_bal)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train SVM with best parameters\n",
    "best_svm = SVC(**grid_search.best_params_, class_weight='balanced')\n",
    "best_svm.fit(X_train_res_bal, y_train_res_bal)\n",
    "\n",
    "# Predict again\n",
    "y_pred_res_bal = best_svm.predict(X_test_res)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Improved Resilience Classification Report:\")\n",
    "print(classification_report(y_test_res, y_pred_res_bal))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_res, y_pred_res_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7dfd696-6172-4339-8c73-586b87a43218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resilience Classification:\n",
      "Macro Precision: 0.6071428571428572\n",
      "Macro Recall: 0.6125\n",
      "Macro F1-score: 0.606060606060606\n",
      "Confusion Matrix:\n",
      " [[5 3]\n",
      " [2 3]]\n",
      "Cognitive Load Classification:\n",
      "Macro Precision: 0.5476190476190476\n",
      "Macro Recall: 0.55\n",
      "Macro F1-score: 0.5357142857142857\n",
      "Confusion Matrix:\n",
      " [[4 4]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# For Resilience\n",
    "precision_res = precision_score(y_test_res, y_pred_res, average='macro')\n",
    "recall_res = recall_score(y_test_res, y_pred_res, average='macro')\n",
    "f1_res = f1_score(y_test_res, y_pred_res, average='macro')\n",
    "conf_matrix_res = confusion_matrix(y_test_res, y_pred_res)\n",
    "\n",
    "print(\"Resilience Classification:\")\n",
    "print(\"Macro Precision:\", precision_res)\n",
    "print(\"Macro Recall:\", recall_res)\n",
    "print(\"Macro F1-score:\", f1_res)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_res)\n",
    "\n",
    "# For Cognitive Load\n",
    "precision_cog = precision_score(y_test_cog, y_pred_cog, average='macro')\n",
    "recall_cog = recall_score(y_test_cog, y_pred_cog, average='macro')\n",
    "f1_cog = f1_score(y_test_cog, y_pred_cog, average='macro')\n",
    "conf_matrix_cog = confusion_matrix(y_test_cog, y_pred_cog)\n",
    "\n",
    "print(\"Cognitive Load Classification:\")\n",
    "print(\"Macro Precision:\", precision_cog)\n",
    "print(\"Macro Recall:\", recall_cog)\n",
    "print(\"Macro F1-score:\", f1_cog)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302cf31-f2f5-4a5a-81fd-265c0fa3944e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
