{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4eec9b-99e3-409a-8ffd-e9dc7dd1393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a61a50d-1178-4252-bd28-86d49710abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resilience_category\n",
      "0    41\n",
      "1    25\n",
      "Name: count, dtype: int64\n",
      "cognitive_load_category\n",
      "0    40\n",
      "1    26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the feature dataset\n",
    "df_eng = pd.read_excel(\"C:/Users/vyache/Downloads/Features_English.xlsx\")\n",
    "\n",
    "# Select only feature columns (replace 'feature_cols' with the actual list of columns)\n",
    "feature_cols = df_eng.columns.difference([\"Recording\", \"Speaker\"])  # Exclude non-feature columns\n",
    "\n",
    "# Standardize the features before applying PCA\n",
    "scaler = StandardScaler()\n",
    "df_eng_scaled = scaler.fit_transform(df_eng[feature_cols])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)  # Adjust number of components as needed\n",
    "principal_components = pca.fit_transform(df_eng_scaled)\n",
    "\n",
    "# Convert PCA output to DataFrame\n",
    "df_pca = pd.DataFrame(principal_components, columns=[f\"PC{i+1}\" for i in range(3)])\n",
    "\n",
    "# Add back identifiers (Recording, Speaker) for merging\n",
    "df_pca[\"Recording\"] = df_eng[\"Recording\"]\n",
    "df_pca[\"Speaker\"] = df_eng[\"Speaker\"]\n",
    "\n",
    "# Load self-report dataset\n",
    "df_self_reports = pd.read_excel(\"C:/Users/vyache/Desktop/Questionnaire data_Eng.xlsx\")\n",
    "\n",
    "# Merge PCA-transformed features with self-reports\n",
    "df_merged = pd.merge(df_pca, df_self_reports, on=[\"Recording\", \"Speaker\"])\n",
    "\n",
    "# Define thresholds for resilience and cognitive load\n",
    "low_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.33)\n",
    "high_threshold_resilience = df_self_reports[\"Emotional Resilience\"].quantile(0.66)\n",
    "\n",
    "low_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.33)\n",
    "high_threshold_load = df_self_reports[\"Cognitive Load\"].quantile(0.66)\n",
    "\n",
    "# Categorization functions for 2 categories (Low vs High)\n",
    "def categorize_resilience(score):\n",
    "    if score < high_threshold_resilience:  # Low resilience\n",
    "        return 0  # Low\n",
    "    else:  # High resilience\n",
    "        return 1  # High\n",
    "\n",
    "def categorize_cognitive_load(score):\n",
    "    if score < high_threshold_load:  # Low cognitive load\n",
    "        return 0  # Low\n",
    "    else:  # High cognitive load\n",
    "        return 1  # High\n",
    "\n",
    "# Apply categorization\n",
    "df_merged[\"resilience_category\"] = df_merged[\"Emotional Resilience\"].apply(categorize_resilience)\n",
    "df_merged[\"cognitive_load_category\"] = df_merged[\"Cognitive Load\"].apply(categorize_cognitive_load)\n",
    "\n",
    "# Verify categories\n",
    "print(df_merged[\"resilience_category\"].value_counts())\n",
    "print(df_merged[\"cognitive_load_category\"].value_counts())\n",
    "\n",
    "# Select PCA features\n",
    "X = df_merged[[\"PC1\", \"PC2\", \"PC3\"]]\n",
    "y_resilience = df_merged[\"resilience_category\"]\n",
    "y_cognitive_load = df_merged[\"cognitive_load_category\"]\n",
    "\n",
    "# Standardize PCA features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6d6b95-81e7-49eb-adeb-4b3708082620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for resilience classification\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(\n",
    "    X_scaled, y_resilience, test_size=0.2, random_state=42, stratify=y_resilience\n",
    ")\n",
    "\n",
    "# Split data for cognitive load classification\n",
    "X_train_cog, X_test_cog, y_train_cog, y_test_cog = train_test_split(\n",
    "    X_scaled, y_cognitive_load, test_size=0.2, random_state=42, stratify=y_cognitive_load\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f3aae0-e407-4742-879e-74259de3e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resilience Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.20      0.20      0.20         5\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.38      0.38      0.38        14\n",
      "weighted avg       0.43      0.43      0.43        14\n",
      "\n",
      "Accuracy: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier for resilience\n",
    "svm_res = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_res = svm_res.predict(X_test_res)\n",
    "\n",
    "# Evaluate resilience classification performance\n",
    "print(\"Resilience Classification Report:\")\n",
    "print(classification_report(y_test_res, y_pred_res))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_res, y_pred_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd15babc-6ad1-4dc2-868a-73ec2d0da8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognitive Load Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70         8\n",
      "           1       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.54      0.52      0.47        14\n",
      "weighted avg       0.55      0.57      0.51        14\n",
      "\n",
      "Accuracy: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier for cognitive load\n",
    "svm_cog = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm_cog.fit(X_train_cog, y_train_cog)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_cog = svm_cog.predict(X_test_cog)\n",
    "\n",
    "# Evaluate cognitive load classification performance\n",
    "print(\"Cognitive Load Classification Report:\")\n",
    "print(classification_report(y_test_cog, y_pred_cog))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cog, y_pred_cog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59596fcd-97ea-4f8c-8d9f-42994feba459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resilience Classification:\n",
      "Macro Precision: 0.37777777777777777\n",
      "Macro Recall: 0.37777777777777777\n",
      "Macro F1-score: 0.37777777777777777\n",
      "Confusion Matrix:\n",
      " [[5 4]\n",
      " [4 1]]\n",
      "Cognitive Load Classification:\n",
      "Macro Precision: 0.5416666666666667\n",
      "Macro Recall: 0.5208333333333334\n",
      "Macro F1-score: 0.475\n",
      "Confusion Matrix:\n",
      " [[7 1]\n",
      " [5 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# For Resilience\n",
    "precision_res = precision_score(y_test_res, y_pred_res, average='macro')\n",
    "recall_res = recall_score(y_test_res, y_pred_res, average='macro')\n",
    "f1_res = f1_score(y_test_res, y_pred_res, average='macro')\n",
    "conf_matrix_res = confusion_matrix(y_test_res, y_pred_res)\n",
    "\n",
    "print(\"Resilience Classification:\")\n",
    "print(\"Macro Precision:\", precision_res)\n",
    "print(\"Macro Recall:\", recall_res)\n",
    "print(\"Macro F1-score:\", f1_res)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_res)\n",
    "\n",
    "# For Cognitive Load\n",
    "precision_cog = precision_score(y_test_cog, y_pred_cog, average='macro')\n",
    "recall_cog = recall_score(y_test_cog, y_pred_cog, average='macro')\n",
    "f1_cog = f1_score(y_test_cog, y_pred_cog, average='macro')\n",
    "conf_matrix_cog = confusion_matrix(y_test_cog, y_pred_cog)\n",
    "\n",
    "print(\"Cognitive Load Classification:\")\n",
    "print(\"Macro Precision:\", precision_cog)\n",
    "print(\"Macro Recall:\", recall_cog)\n",
    "print(\"Macro F1-score:\", f1_cog)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_cog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47613bdc-b172-4ac7-9856-04510c7adcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
